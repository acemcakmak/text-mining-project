{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import nltk\n",
    "from nltk.sentiment import vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import os\n",
    "import spacy\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import pathlib\n",
    "import sklearn\n",
    "import numpy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'text': \"I wouldn't be caught dead watching the NFL if it weren't for Taylor Swift.\", 'sentiment': 'negative', 'topic': 'sports'}}\n",
      "{1: {'text': \"Chris O'Donnell stated that while filming for this movie, he felt like he was in a Toys ''R'' Us commercial.\", 'sentiment': 'neutral', 'topic': 'movie'}}\n",
      "{2: {'text': 'The whole game was a rollercoaster ride, but Los Angeles Lakers ultimately persevered and won!', 'sentiment': 'positive', 'topic': 'sports'}}\n",
      "{3: {'text': 'Zendaya slayed in Dune 2, as she does in all her movies.', 'sentiment': 'positive', 'topic': 'movie'}}\n",
      "{4: {'text': \"While my favorite player was playing this match and started off strongggg, it went downhill after Messi's injyry midgame.\", 'sentiment': 'negative', 'topic': 'sports'}}\n",
      "{5: {'text': \"My uncle's brother's neighbor's cat's veterinarian David reads the communist manifesto in his spare time.\", 'sentiment': 'neutral', 'topic': 'book'}}\n",
      "{6: {'text': 'He said that The Great Gatsby is the best novell ever, and I was about to throw hands.', 'sentiment': 'negative', 'topic': 'book'}}\n",
      "{7: {'text': 'I could not look away from this train wrck of a movie, on February 14th of all days.', 'sentiment': 'negative', 'topic': 'movie'}}\n",
      "{8: {'text': \"The film Everything Everywhere All At Once follows Evelyn Wang, a woman drowning under the stress of her family's failing laundromat.\", 'sentiment': 'neutral', 'topic': 'movie'}}\n",
      "{9: {'text': 'I just finished reading pride and prejudice which had me HOOOKED from the beginning.', 'sentiment': 'positive', 'topic': 'book'}}\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/acemcakmak/Desktop/text-mining-project/sentiment-topic-test.tsv\"\n",
    "sentences = {}\n",
    "with open(path, \"r\") as testFile: \n",
    "    testFile.readline()\n",
    "    for row in testFile.readlines(): \n",
    "        elements = row.split(\"\\t\")\n",
    "        sentences[elements[0]] = {\"text\":elements[1], \"sentiment\":elements[2], \"topic\": elements[3].replace(\"\\n\", \"\")}\n",
    "\n",
    "for key, value in sentences.items(): \n",
    "    print(\"{\" + key + \": \" + str(value) + \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I wouldn't be caught dead watching the NFL if it weren't for Taylor Swift.\", \"Chris O'Donnell stated that while filming for this movie, he felt like he was in a Toys ''R'' Us commercial.\", 'The whole game was a rollercoaster ride, but Los Angeles Lakers ultimately persevered and won!', 'Zendaya slayed in Dune 2, as she does in all her movies.', \"While my favorite player was playing this match and started off strongggg, it went downhill after Messi's injyry midgame.\", \"My uncle's brother's neighbor's cat's veterinarian David reads the communist manifesto in his spare time.\", 'He said that The Great Gatsby is the best novell ever, and I was about to throw hands.', 'I could not look away from this train wrck of a movie, on February 14th of all days.', \"The film Everything Everywhere All At Once follows Evelyn Wang, a woman drowning under the stress of her family's failing laundromat.\", 'I just finished reading pride and prejudice which had me HOOOKED from the beginning.']\n"
     ]
    }
   ],
   "source": [
    "test_sentences = []\n",
    "for key, value in sentences.items(): \n",
    "    test_sentences.append(value[\"text\"])\n",
    "print(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 6780\n",
      "Categories: ['negative', 'neutral', 'positive']\n",
      "Shape of test data: (1, 41887)\n",
      "'@airline I am so happy!!!!!.' => negative\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import sklearn\n",
    "import numpy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "test_sentences = [\"@airline I am so happy!!!!!.\"]\n",
    "cwd = pathlib.Path.cwd()\n",
    "sentiment_folder = cwd.joinpath('sentiment-train')\n",
    "if not sentiment_folder.exists():\n",
    "    print('error: path does not exist:', sentiment_folder)\n",
    "\n",
    "sentiment_train = load_files(str(sentiment_folder))\n",
    "print(\"Number of training samples:\", len(sentiment_train.data))\n",
    "print(\"Categories:\", sentiment_train.target_names)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(sentiment_train.data)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, sentiment_train.target)\n",
    "\n",
    "X_new_counts = count_vect.transform(test_sentences)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "print(\"Shape of test data:\", X_new_tfidf.shape)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "for doc, category in zip(test_sentences, predicted):\n",
    "     print('%r => %s' % (doc, sentiment_train.target_names[category]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
