{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import nltk\n",
    "import os\n",
    "import spacy\n",
    "import sklearn\n",
    "import numpy\n",
    "import pathlib\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'text': \"I wouldn't be caught dead watching the NFL if it weren't for Taylor Swift.\", 'sentiment': 'negative', 'topic': 'sports'}}\n",
      "{1: {'text': \"Chris O'Donnell stated that while filming for this movie, he felt like he was in a Toys ''R'' Us commercial.\", 'sentiment': 'neutral', 'topic': 'movie'}}\n",
      "{2: {'text': 'The whole game was a rollercoaster ride, but Los Angeles Lakers ultimately persevered and won!', 'sentiment': 'positive', 'topic': 'sports'}}\n",
      "{3: {'text': 'Zendaya slayed in Dune 2, as she does in all her movies.', 'sentiment': 'positive', 'topic': 'movie'}}\n",
      "{4: {'text': \"While my favorite player was playing this match and started off strongggg, it went downhill after Messi's injyry midgame.\", 'sentiment': 'negative', 'topic': 'sports'}}\n",
      "{5: {'text': \"My uncle's brother's neighbor's cat's veterinarian David reads the communist manifesto in his spare time.\", 'sentiment': 'neutral', 'topic': 'book'}}\n",
      "{6: {'text': 'He said that The Great Gatsby is the best novell ever, and I was about to throw hands.', 'sentiment': 'negative', 'topic': 'book'}}\n",
      "{7: {'text': 'I could not look away from this train wrck of a movie, on February 14th of all days.', 'sentiment': 'negative', 'topic': 'movie'}}\n",
      "{8: {'text': \"The film Everything Everywhere All At Once follows Evelyn Wang, a woman drowning under the stress of her family's failing laundromat.\", 'sentiment': 'neutral', 'topic': 'movie'}}\n",
      "{9: {'text': 'I just finished reading pride and prejudice which had me HOOOKED from the beginning.', 'sentiment': 'positive', 'topic': 'book'}}\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/acemcakmak/Desktop/text-mining-project/sentiment-topic-test.tsv\"\n",
    "sentences = {}\n",
    "with open(path, \"r\") as testFile: \n",
    "    testFile.readline()\n",
    "    for row in testFile.readlines(): \n",
    "        elements = row.split(\"\\t\")\n",
    "        sentences[elements[0]] = {\"text\":elements[1], \"sentiment\":elements[2], \"topic\": elements[3].replace(\"\\n\", \"\")}\n",
    "\n",
    "for key, value in sentences.items(): \n",
    "    print(\"{\" + key + \": \" + str(value) + \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I wouldn't be caught dead watching the NFL if it weren't for Taylor Swift.\", \"Chris O'Donnell stated that while filming for this movie, he felt like he was in a Toys ''R'' Us commercial.\", 'The whole game was a rollercoaster ride, but Los Angeles Lakers ultimately persevered and won!', 'Zendaya slayed in Dune 2, as she does in all her movies.', \"While my favorite player was playing this match and started off strongggg, it went downhill after Messi's injyry midgame.\", \"My uncle's brother's neighbor's cat's veterinarian David reads the communist manifesto in his spare time.\", 'He said that The Great Gatsby is the best novell ever, and I was about to throw hands.', 'I could not look away from this train wrck of a movie, on February 14th of all days.', \"The film Everything Everywhere All At Once follows Evelyn Wang, a woman drowning under the stress of her family's failing laundromat.\", 'I just finished reading pride and prejudice which had me HOOOKED from the beginning.']\n"
     ]
    }
   ],
   "source": [
    "test_sentences = []\n",
    "for key, value in sentences.items(): \n",
    "    test_sentences.append(value[\"text\"])\n",
    "print(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'neutral', 'positive', 'positive', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'positive']\n"
     ]
    }
   ],
   "source": [
    "true_sentiments = []\n",
    "for key, value in sentences.items(): \n",
    "    true_sentiments.append(value[\"sentiment\"])\n",
    "print(true_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 2000\n",
      "Categories: ['negative', 'positive']\n",
      "Shape of test data: (10, 39659)\n",
      "\"I wouldn't be caught dead watching the NFL if it weren't for Taylor Swift.\" => negative\n",
      "\"Chris O'Donnell stated that while filming for this movie, he felt like he was in a Toys ''R'' Us commercial.\" => negative\n",
      "'The whole game was a rollercoaster ride, but Los Angeles Lakers ultimately persevered and won!' => positive\n",
      "'Zendaya slayed in Dune 2, as she does in all her movies.' => negative\n",
      "\"While my favorite player was playing this match and started off strongggg, it went downhill after Messi's injyry midgame.\" => negative\n",
      "\"My uncle's brother's neighbor's cat's veterinarian David reads the communist manifesto in his spare time.\" => positive\n",
      "'He said that The Great Gatsby is the best novell ever, and I was about to throw hands.' => negative\n",
      "'I could not look away from this train wrck of a movie, on February 14th of all days.' => negative\n",
      "\"The film Everything Everywhere All At Once follows Evelyn Wang, a woman drowning under the stress of her family's failing laundromat.\" => positive\n",
      "'I just finished reading pride and prejudice which had me HOOOKED from the beginning.' => positive\n",
      "['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'positive']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative      0.667     1.000     0.800         4\n",
      "    positive      0.500     0.667     0.571         3\n",
      "\n",
      "   micro avg      0.600     0.857     0.706         7\n",
      "   macro avg      0.583     0.833     0.686         7\n",
      "weighted avg      0.595     0.857     0.702         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "sentiment_folder = cwd.joinpath('bipolar-sentiment-train-v1')\n",
    "if not sentiment_folder.exists():\n",
    "    print('error: path does not exist:', sentiment_folder)\n",
    "\n",
    "sentiment_train = load_files(str(sentiment_folder))\n",
    "print(\"Number of training samples:\", len(sentiment_train.data))\n",
    "print(\"Categories:\", sentiment_train.target_names)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(sentiment_train.data)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, sentiment_train.target)\n",
    "\n",
    "X_new_counts = count_vect.transform(test_sentences)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "print(\"Shape of test data:\", X_new_tfidf.shape)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "predicted_sentiments = []\n",
    "for doc, category in zip(test_sentences, predicted):\n",
    "     print('%r => %s' % (doc, sentiment_train.target_names[category]))\n",
    "     predicted_sentiments.append(sentiment_train.target_names[category])\n",
    "print(predicted_sentiments)\n",
    "print(\"\\n\")\n",
    "print(classification_report(true_sentiments, predicted_sentiments, labels=sentiment_train.target_names, target_names=sentiment_train.target_names, digits = 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 15662\n",
      "Categories: ['negative', 'neutral', 'positive']\n",
      "Shape of test data: (10, 24682)\n",
      "\"I wouldn't be caught dead watching the NFL if it weren't for Taylor Swift.\" => negative\n",
      "\"Chris O'Donnell stated that while filming for this movie, he felt like he was in a Toys ''R'' Us commercial.\" => negative\n",
      "'The whole game was a rollercoaster ride, but Los Angeles Lakers ultimately persevered and won!' => neutral\n",
      "'Zendaya slayed in Dune 2, as she does in all her movies.' => neutral\n",
      "\"While my favorite player was playing this match and started off strongggg, it went downhill after Messi's injyry midgame.\" => negative\n",
      "\"My uncle's brother's neighbor's cat's veterinarian David reads the communist manifesto in his spare time.\" => neutral\n",
      "'He said that The Great Gatsby is the best novell ever, and I was about to throw hands.' => neutral\n",
      "'I could not look away from this train wrck of a movie, on February 14th of all days.' => negative\n",
      "\"The film Everything Everywhere All At Once follows Evelyn Wang, a woman drowning under the stress of her family's failing laundromat.\" => neutral\n",
      "'I just finished reading pride and prejudice which had me HOOOKED from the beginning.' => negative\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "sentiment_folder = cwd.joinpath('tripolar-sentiment-train-v1')\n",
    "if not sentiment_folder.exists():\n",
    "    print('error: path does not exist:', sentiment_folder)\n",
    "\n",
    "sentiment_train = load_files(str(sentiment_folder))\n",
    "print(\"Number of training samples:\", len(sentiment_train.data))\n",
    "print(\"Categories:\", sentiment_train.target_names)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(sentiment_train.data)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, sentiment_train.target)\n",
    "\n",
    "X_new_counts = count_vect.transform(test_sentences)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "print(\"Shape of test data:\", X_new_tfidf.shape)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "for doc, category in zip(test_sentences, predicted):\n",
    "     print('%r => %s' % (doc, sentiment_train.target_names[category]))\n",
    "     predicted_sentiments.append(sentiment_train.target_names[category])\n",
    "print(predicted_sentiments)\n",
    "print(\"\\n\")\n",
    "print(classification_report(true_sentiments, predicted_sentiments, labels=sentiment_train.target_names, target_names=sentiment_train.target_names, digits = 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 30000\n",
      "Categories: ['negative', 'neutral', 'positive']\n",
      "Shape of test data: (10, 48929)\n",
      "\"I wouldn't be caught dead watching the NFL if it weren't for Taylor Swift.\" => negative\n",
      "\"Chris O'Donnell stated that while filming for this movie, he felt like he was in a Toys ''R'' Us commercial.\" => positive\n",
      "'The whole game was a rollercoaster ride, but Los Angeles Lakers ultimately persevered and won!' => negative\n",
      "'Zendaya slayed in Dune 2, as she does in all her movies.' => negative\n",
      "\"While my favorite player was playing this match and started off strongggg, it went downhill after Messi's injyry midgame.\" => negative\n",
      "\"My uncle's brother's neighbor's cat's veterinarian David reads the communist manifesto in his spare time.\" => positive\n",
      "'He said that The Great Gatsby is the best novell ever, and I was about to throw hands.' => negative\n",
      "'I could not look away from this train wrck of a movie, on February 14th of all days.' => negative\n",
      "\"The film Everything Everywhere All At Once follows Evelyn Wang, a woman drowning under the stress of her family's failing laundromat.\" => positive\n",
      "'I just finished reading pride and prejudice which had me HOOOKED from the beginning.' => positive\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "sentiment_folder = cwd.joinpath('tripolar-sentiment-train-v2')\n",
    "if not sentiment_folder.exists():\n",
    "    print('error: path does not exist:', sentiment_folder)\n",
    "\n",
    "sentiment_train = load_files(str(sentiment_folder))\n",
    "print(\"Number of training samples:\", len(sentiment_train.data))\n",
    "print(\"Categories:\", sentiment_train.target_names)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(sentiment_train.data)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, sentiment_train.target)\n",
    "\n",
    "X_new_counts = count_vect.transform(test_sentences)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "print(\"Shape of test data:\", X_new_tfidf.shape)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "for doc, category in zip(test_sentences, predicted):\n",
    "     print('%r => %s' % (doc, sentiment_train.target_names[category]))\n",
    "     predicted_sentiments.append(sentiment_train.target_names[category])\n",
    "print(predicted_sentiments)\n",
    "print(\"\\n\")\n",
    "print(classification_report(true_sentiments, predicted_sentiments, labels=sentiment_train.target_names, target_names=sentiment_train.target_names, digits = 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Sentence: I wouldn't be caught dead watching the NFL if it weren't for Taylor Swift.\n",
      "Input to VADER: ['I', 'would', \"n't\", 'be', 'caught', 'dead', 'watching', 'the', 'NFL', 'if', 'it', 'were', \"n't\", 'for', 'Taylor', 'Swift', '.']\n",
      "VADER Output: {'neg': 0.088, 'neu': 0.721, 'pos': 0.191, 'compound': 0.431}\n",
      "VADER Result: positive\n",
      "\n",
      "Input Sentence: Chris O'Donnell stated that while filming for this movie, he felt like he was in a Toys ''R'' Us commercial.\n",
      "Input to VADER: ['Chris', \"O'Donnell\", 'stated', 'that', 'while', 'filming', 'for', 'this', 'movie', ',', 'he', 'felt', 'like', 'he', 'was', 'in', 'a', 'Toys', \"''\", 'R', \"''\", 'Us', 'commercial', '.']\n",
      "VADER Output: {'neg': 0.0, 'neu': 0.884, 'pos': 0.116, 'compound': 0.3612}\n",
      "VADER Result: positive\n",
      "\n",
      "Input Sentence: The whole game was a rollercoaster ride, but Los Angeles Lakers ultimately persevered and won!\n",
      "Input to VADER: ['The', 'whole', 'game', 'was', 'a', 'rollercoaster', 'ride', ',', 'but', 'Los', 'Angeles', 'Lakers', 'ultimately', 'persevered', 'and', 'won', '!']\n",
      "VADER Output: {'neg': 0.0, 'neu': 0.709, 'pos': 0.291, 'compound': 0.7463}\n",
      "VADER Result: positive\n",
      "\n",
      "Input Sentence: Zendaya slayed in Dune 2, as she does in all her movies.\n",
      "Input to VADER: ['Zendaya', 'slayed', 'in', 'Dune', '2', ',', 'as', 'she', 'does', 'in', 'all', 'her', 'movies', '.']\n",
      "VADER Output: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "VADER Result: neutral\n",
      "\n",
      "Input Sentence: While my favorite player was playing this match and started off strongggg, it went downhill after Messi's injyry midgame.\n",
      "Input to VADER: ['While', 'my', 'favorite', 'player', 'was', 'playing', 'this', 'match', 'and', 'started', 'off', 'strongggg', ',', 'it', 'went', 'downhill', 'after', 'Messi', \"'s\", 'injyry', 'midgame', '.']\n",
      "VADER Output: {'neg': 0.0, 'neu': 0.789, 'pos': 0.211, 'compound': 0.5859}\n",
      "VADER Result: positive\n",
      "\n",
      "Input Sentence: My uncle's brother's neighbor's cat's veterinarian David reads the communist manifesto in his spare time.\n",
      "Input to VADER: ['My', 'uncle', \"'s\", 'brother', \"'s\", 'neighbor', \"'s\", 'cat', \"'s\", 'veterinarian', 'David', 'reads', 'the', 'communist', 'manifesto', 'in', 'his', 'spare', 'time', '.']\n",
      "VADER Output: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "VADER Result: neutral\n",
      "\n",
      "Input Sentence: He said that The Great Gatsby is the best novell ever, and I was about to throw hands.\n",
      "Input to VADER: ['He', 'said', 'that', 'The', 'Great', 'Gatsby', 'is', 'the', 'best', 'novell', 'ever', ',', 'and', 'I', 'was', 'about', 'to', 'throw', 'hands', '.']\n",
      "VADER Output: {'neg': 0.0, 'neu': 0.644, 'pos': 0.356, 'compound': 0.8519}\n",
      "VADER Result: positive\n",
      "\n",
      "Input Sentence: I could not look away from this train wrck of a movie, on February 14th of all days.\n",
      "Input to VADER: ['I', 'could', 'not', 'look', 'away', 'from', 'this', 'train', 'wrck', 'of', 'a', 'movie', ',', 'on', 'February', '14th', 'of', 'all', 'days', '.']\n",
      "VADER Output: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "VADER Result: neutral\n",
      "\n",
      "Input Sentence: The film Everything Everywhere All At Once follows Evelyn Wang, a woman drowning under the stress of her family's failing laundromat.\n",
      "Input to VADER: ['The', 'film', 'Everything', 'Everywhere', 'All', 'At', 'Once', 'follows', 'Evelyn', 'Wang', ',', 'a', 'woman', 'drowning', 'under', 'the', 'stress', 'of', 'her', 'family', \"'s\", 'failing', 'laundromat', '.']\n",
      "VADER Output: {'neg': 0.243, 'neu': 0.757, 'pos': 0.0, 'compound': -0.7269}\n",
      "VADER Result: negative\n",
      "\n",
      "Input Sentence: I just finished reading pride and prejudice which had me HOOOKED from the beginning.\n",
      "Input to VADER: ['I', 'just', 'finished', 'reading', 'pride', 'and', 'prejudice', 'which', 'had', 'me', 'HOOOKED', 'from', 'the', 'beginning', '.']\n",
      "VADER Output: {'neg': 0.198, 'neu': 0.659, 'pos': 0.144, 'compound': -0.2263}\n",
      "VADER Result: negative\n"
     ]
    }
   ],
   "source": [
    "vader_model = SentimentIntensityAnalyzer()\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def run_vader(textual_unit, lemmatize=False, parts_of_speech_to_consider=None, verbose=0):\n",
    "    doc = nlp(textual_unit)\n",
    "    input_to_vader = []\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            to_add = token.text\n",
    "            if lemmatize:\n",
    "                to_add = token.lemma_\n",
    "                if to_add == '-PRON-': \n",
    "                    to_add = token.text\n",
    "            if parts_of_speech_to_consider:\n",
    "                if token.pos_ in parts_of_speech_to_consider:\n",
    "                    input_to_vader.append(to_add) \n",
    "            else:\n",
    "                input_to_vader.append(to_add)\n",
    "\n",
    "    scores = vader_model.polarity_scores(' '.join(input_to_vader))\n",
    "    \n",
    "    if verbose >= 1:\n",
    "        print()\n",
    "        print('Input Sentence:', sent)\n",
    "        print('Input to VADER:', input_to_vader)\n",
    "        print('VADER Output:', scores)\n",
    "\n",
    "    return scores\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    scores = run_vader(sentence, verbose=1)\n",
    "    compound_score = scores[\"compound\"]\n",
    "    if compound_score > 0.05:\n",
    "        print(\"VADER Result: positive\")\n",
    "    elif compound_score < -0.05:\n",
    "        print(\"VADER Result: negative\")\n",
    "    else:\n",
    "        print(\"VADER Result: neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 27480\n",
      "Categories: ['negative', 'neutral', 'positive']\n",
      "Shape of test data: (10, 26438)\n",
      "\"I wouldn't be caught dead watching the NFL if it weren't for Taylor Swift.\" => neutral\n",
      "\"Chris O'Donnell stated that while filming for this movie, he felt like he was in a Toys ''R'' Us commercial.\" => neutral\n",
      "'The whole game was a rollercoaster ride, but Los Angeles Lakers ultimately persevered and won!' => neutral\n",
      "'Zendaya slayed in Dune 2, as she does in all her movies.' => neutral\n",
      "\"While my favorite player was playing this match and started off strongggg, it went downhill after Messi's injyry midgame.\" => neutral\n",
      "\"My uncle's brother's neighbor's cat's veterinarian David reads the communist manifesto in his spare time.\" => neutral\n",
      "'He said that The Great Gatsby is the best novell ever, and I was about to throw hands.' => positive\n",
      "'I could not look away from this train wrck of a movie, on February 14th of all days.' => neutral\n",
      "\"The film Everything Everywhere All At Once follows Evelyn Wang, a woman drowning under the stress of her family's failing laundromat.\" => neutral\n",
      "'I just finished reading pride and prejudice which had me HOOOKED from the beginning.' => neutral\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "sentiment_folder = cwd.joinpath('tripolar-sentiment-train-v3')\n",
    "if not sentiment_folder.exists():\n",
    "    print('error: path does not exist:', sentiment_folder)\n",
    "\n",
    "sentiment_train = load_files(str(sentiment_folder))\n",
    "print(\"Number of training samples:\", len(sentiment_train.data))\n",
    "print(\"Categories:\", sentiment_train.target_names)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(sentiment_train.data)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, sentiment_train.target)\n",
    "\n",
    "X_new_counts = count_vect.transform(test_sentences)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "print(\"Shape of test data:\", X_new_tfidf.shape)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "for doc, category in zip(test_sentences, predicted):\n",
    "     predicted_sentiments.append(sentiment_train.target_names[category])\n",
    "print(predicted_sentiments)\n",
    "print(\"\\n\")\n",
    "print(classification_report(true_sentiments, predicted_sentiments, labels=sentiment_train.target_names, target_names=sentiment_train.target_names, digits = 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 10000\n",
      "Categories: ['objective', 'subjective']\n",
      "Shape of test data: (10, 20893)\n",
      "\"I wouldn't be caught dead watching the NFL if it weren't for Taylor Swift.\" => subjective\n",
      "\"Chris O'Donnell stated that while filming for this movie, he felt like he was in a Toys ''R'' Us commercial.\" => subjective\n",
      "'The whole game was a rollercoaster ride, but Los Angeles Lakers ultimately persevered and won!' => objective\n",
      "'Zendaya slayed in Dune 2, as she does in all her movies.' => objective\n",
      "\"While my favorite player was playing this match and started off strongggg, it went downhill after Messi's injyry midgame.\" => subjective\n",
      "\"My uncle's brother's neighbor's cat's veterinarian David reads the communist manifesto in his spare time.\" => objective\n",
      "'He said that The Great Gatsby is the best novell ever, and I was about to throw hands.' => subjective\n",
      "'I could not look away from this train wrck of a movie, on February 14th of all days.' => objective\n",
      "\"The film Everything Everywhere All At Once follows Evelyn Wang, a woman drowning under the stress of her family's failing laundromat.\" => objective\n",
      "'I just finished reading pride and prejudice which had me HOOOKED from the beginning.' => subjective\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "sentiment_folder = cwd.joinpath('bipolar-sentiment-train-v2')\n",
    "if not sentiment_folder.exists():\n",
    "    print('error: path does not exist:', sentiment_folder)\n",
    "\n",
    "sentiment_train = load_files(str(sentiment_folder))\n",
    "print(\"Number of training samples:\", len(sentiment_train.data))\n",
    "print(\"Categories:\", sentiment_train.target_names)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(sentiment_train.data)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, sentiment_train.target)\n",
    "\n",
    "X_new_counts = count_vect.transform(test_sentences)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "print(\"Shape of test data:\", X_new_tfidf.shape)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "for doc, category in zip(test_sentences, predicted):\n",
    "     predicted_sentiments.append(sentiment_train.target_names[category])\n",
    "print(predicted_sentiments)\n",
    "print(\"\\n\")\n",
    "print(classification_report(true_sentiments, predicted_sentiments, labels=sentiment_train.target_names, target_names=sentiment_train.target_names, digits = 3))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
